{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c36fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7594904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c6f895",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from MyVAE import MyVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6561ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will crop the image to remove the top and bottom (those are always white)\n",
    "crop_dim = (150, 0, 400, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336f13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after the crop, we will reduce the image size to these dimensions for faster training\n",
    "img_dim = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "563000a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5d6709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae():\n",
    "\n",
    "    # initialize the gym environment\n",
    "    #########################\n",
    "\n",
    "    # try different environments\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "    #########################\n",
    "    # first observation from the environment\n",
    "    obs = env.reset()\n",
    "\n",
    "    # VAE\n",
    "\n",
    "    input_channels = 3\n",
    "    latent_dim = 10\n",
    "    training_size = 100000\n",
    "    batch_size = latent_dim * 10\n",
    "    n_epochs = 400\n",
    "\n",
    "    # initialize the VAE\n",
    "    # VAE model\n",
    "    vae = MyVAE(\n",
    "        in_channels = input_channels,\n",
    "        latent_dim = latent_dim,\n",
    "    ).to(device)\n",
    "    optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "\n",
    "    imgs = np.zeros((training_size, input_channels, *img_dim), dtype=np.float32)\n",
    "\n",
    "    # Collect pixel data from the gym\n",
    "\n",
    "    # episode frame counter\n",
    "    frame_idx = 0\n",
    "\n",
    "    for i in range(training_size):\n",
    "        frame_idx += 1\n",
    "\n",
    "        # get a random action in this environment\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        # obs is observation data from the env. \n",
    "        # Look at the gym code to find which one is a pole angle. \n",
    "        # https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py\n",
    "        obs, reward, done, info = env.step(action) # pole angle \"Done\" : -24 degrees, or -.418 radians\n",
    "\n",
    "        # get pixel observations, crop, and resize\n",
    "        img = env.render(mode='rgb_array')\n",
    "        img = img[crop_dim[0]: crop_dim[2], crop_dim[1]: crop_dim[3], :]\n",
    "        img = cv2.resize(img, dsize=img_dim, interpolation=cv2.INTER_CUBIC)\n",
    "        # how the model will see the image after crop and resize\n",
    "        # cv2.imshow('img', img)\n",
    "        # cv2.waitKey(1)\n",
    "        img = img.swapaxes(0, 2).reshape((1, input_channels, *img_dim)).astype(np.float32) / 255.0\n",
    "\n",
    "        #################\n",
    "\n",
    "        # add some conditional logic to save the images you need\n",
    "        # collect data\n",
    "        # if obs???:\n",
    "        imgs[i] = img\n",
    "\n",
    "        #################\n",
    "\n",
    "        #################\n",
    "\n",
    "        # update the reset conditions to save the images you need\n",
    "        # if ???:\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            frame_idx = 0\n",
    "\n",
    "        #################\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    # visualization init\n",
    "    plt.ion()\n",
    "    plt.show()\n",
    "\n",
    "    # train VAE\n",
    "    for i in range(n_epochs):\n",
    "        # observations for cvae to use as labels\n",
    "        start_idx = random.randint(0, training_size - batch_size)\n",
    "\n",
    "        train_imgs = imgs[start_idx : start_idx + batch_size]\n",
    "\n",
    "        out_imgs = vae(\n",
    "            torch.from_numpy(train_imgs.copy()).to(device),\n",
    "        )\n",
    "        loss = vae.loss(*out_imgs, kl_w=0.0005)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(loss)\n",
    "\n",
    "        # get a few generated images\n",
    "        rand_idx = np.random.randint(0, batch_size - 1)\n",
    "        im = out_imgs[0][rand_idx: rand_idx + 1].detach().cpu().numpy().reshape(\n",
    "            (1, 3, *img_dim)).swapaxes(1, 3)\n",
    "        im = (im * 255.0).astype(np.uint8)\n",
    "\n",
    "        # show generated image\n",
    "        plt.subplot(\n",
    "            np.ceil(np.sqrt(1 * n_epochs)).astype(int),\n",
    "            np.ceil(np.sqrt(1 * n_epochs)).astype(int),\n",
    "            i + 1\n",
    "        )\n",
    "        plt.imshow(im[0], aspect='auto')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        plt.pause(0.1)\n",
    "\n",
    "    # save our model\n",
    "    torch.save(vae.state_dict(), 'vae.pth')\n",
    "    plt.savefig('vae_training.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94a68ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OutStream' object has no attribute '_exc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\envs\\toy_text\\frozen_lake.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'OutStream' object has no attribute 'getvalue'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22680/1104384897.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain_vae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22680/563526095.py\u001b[0m in \u001b[0;36mtrain_vae\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m# get pixel observations, crop, and resize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcrop_dim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcrop_dim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop_dim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcrop_dim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"human\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\envs\\toy_text\\frozen_lake.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"human\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, *exc_info)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_watch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch_fd_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m             \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OutStream' object has no attribute '_exc'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f793779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
